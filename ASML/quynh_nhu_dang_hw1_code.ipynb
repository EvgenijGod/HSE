{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Домашняя работа № 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Данг Куинь Ньы, БПМИ182"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[scipy: base class to construct specific distribution classes and instances for continuous random variables](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.rv_continuous.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import rv_continuous\n",
    "class custom_gen(rv_continuous):\n",
    "    def _pdf(self, x, q):\n",
    "        if not (x > 0): return 0    # check if x > 0\n",
    "        return (2 * x / q) * np.exp(-1 / q * (x ** 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate sample\n",
    "unf_curses = custom_gen(name='unforgivable curses')\n",
    "x2 = unf_curses.rvs(size=1273, q=5)    # true value of q = 5, sample size = 1273"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log of likelihood function\n",
    "def loglike(q, x):\n",
    "    n = len(x)\n",
    "    return n * np.log(2 / q) + np.sum(np.log(x)) - np.sum(x**2) / q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimization of loglike function\n",
    "def opt_loglike(q, x):    \n",
    "    return -loglike(q, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Найдём оценку $\\hat{q}$. Поскольку $f(x) = x^2$ - гладкая функция, оценка $\\widehat{q^2} = (\\hat{q})^2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computed estimate of q and q**2 values: 4.9926 24.9256\n"
     ]
    }
   ],
   "source": [
    "from scipy import optimize\n",
    "q_hat = optimize.minimize(opt_loglike, 0.001, x2, method = 'Nelder-Mead')['x'][0]\n",
    "print('Computed estimate of q and q**2 values: %.4f %.4f' % (q_hat, q_hat ** 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для сравнения выведем теоретическую оценку параметра $\\hat{q} = \\overline{X^2}$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculated estimate of q and q**2 values: 4.9925 24.9254\n"
     ]
    }
   ],
   "source": [
    "q_hat_theory = np.mean(x2 ** 2)\n",
    "print('Calculated estimate of q and q**2 values: %.4f %.4f' % (q_hat_theory, q_hat_theory ** 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функцию правдоподобия (точнее, логарифм от неё) оптимизировали, взяв её со знаком минус (аналогично оптимизации в семинаре 1). Оценка находится уже минимизацией преобразованной функции, дополнительных трудностей не возникло. Как видно, оценка (с начальным приближением 0.001) находится довольно точно - при истинном значении 5 выдаётся оценка 4.9926."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Симулируем 300 наблюдений ($x_i, y_i$) таким образом, что $x_i \\sim \\mathcal{N}(0, 1), \\, \\, \\,y_i = 3e^{x_i}u_i, \\, \\, \\, \\ln{u_i} \\sim \\mathcal{N}(0,1)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate sample\n",
    "np.random.seed(1234)\n",
    "x = np.random.normal(0, 1, 300)\n",
    "lnu = np.random.normal(0, 1, 300)\n",
    "y = 3 * np.exp(x + lnu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посчитаем оценки $\\hat{\\beta_1}$ и $\\hat{\\beta_2}$ (общий вид найден в теоретической части задачи):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\hat{\\beta_2} = \\frac{\\sum\\limits_{i=1}^{n}x_i(\\ln{y_i}-\\overline{\\ln{y}})}{\\sum\\limits_{i=1}^{n}x_i(x_i - \\overline{x})}$$\n",
    "$$\\ln{\\hat{\\beta_1}} = \\overline{\\ln{y}} - \\hat{\\beta_2}\\overline{x} \\iff \\hat{\\beta_1} = \\prod\\limits_{i=1}^{n}y_i^{\\frac{1}{n}} \\cdot \\exp{(-\\hat{\\beta_2}\\overline{x})}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculated estimates\n",
    "n = len(x)\n",
    "hat_beta2 = np.sum(x * (np.log(y) - np.mean(np.log(y)))) / np.sum(x * (x - np.mean(x)))\n",
    "hat_beta1 = np.prod(y ** (1 / n)) * np.exp(-hat_beta2 * np.mean(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters estimates: 3.0285, 0.9529\n"
     ]
    }
   ],
   "source": [
    "print('Parameters estimates: %.4f, %.4f' %(hat_beta1, hat_beta2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим гипотезу\n",
    "\n",
    "$$H_0 :\n",
    "\\begin{pmatrix}\n",
    "    \\beta_1 \\\\\n",
    "    \\beta_2\n",
    "\\end{pmatrix} =\n",
    "\\begin{pmatrix}\n",
    "    1 \\\\\n",
    "    2\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "против\n",
    "$$H_A :\n",
    "\\begin{pmatrix}\n",
    "    \\beta_1 \\\\\n",
    "    \\beta_2\n",
    "\\end{pmatrix} \\neq\n",
    "\\begin{pmatrix}\n",
    "    1 \\\\\n",
    "    2\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "на уровне значимости 5% при помощи теста $LR$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log of likelihood function\n",
    "def loglike4(beta, x, y):\n",
    "    n = len(x)\n",
    "    beta1 = beta[0]\n",
    "    beta2 = beta[1]\n",
    "    return - n / 2 * np.log(2 * np.pi) - 1 / 2 * np.sum((np.log(y) - np.log(beta1) - beta2 * x)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value of LR test: 650.5304\n"
     ]
    }
   ],
   "source": [
    "# LR test\n",
    "lr = 2 * (loglike4((hat_beta1, hat_beta2), x, y) - loglike4((1, 2), x, y))\n",
    "print('Value of LR test: %.4f' % lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Критическое значение $\\chi^2_{2}$ равно $5.99 << LR$, значит, гипотеза опровергается."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
