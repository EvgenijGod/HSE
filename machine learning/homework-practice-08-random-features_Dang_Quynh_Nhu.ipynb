{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RYp0bXOFK-hP"
   },
   "source": [
    "# Машинное обучение, ФКН ВШЭ\n",
    "\n",
    "## Практическое задание 8. Метод опорных векторов и аппроксимация ядер\n",
    "\n",
    "### Общая информация\n",
    "Дата выдачи: 05.02.2021\n",
    "\n",
    "Мягкий дедлайн: 01:59MSK 21.02.2021\n",
    "\n",
    "Жесткий дедлайн: 01:59MSK 24.02.2021\n",
    "\n",
    "### Оценивание и штрафы\n",
    "Каждая из задач имеет определенную «стоимость» (указана в скобках около задачи). Максимальная оценка за работу (без учёта бонусов) — 10 баллов.\n",
    "\n",
    "Сдавать задание после указанного жёсткого срока сдачи нельзя. При выставлении неполного балла за задание в связи с наличием ошибок на усмотрение проверяющего предусмотрена возможность исправить работу на указанных в ответном письме условиях.\n",
    "\n",
    "Задание выполняется самостоятельно. «Похожие» решения считаются плагиатом и все задействованные студенты (в том числе те, у кого списали) не могут получить за него больше 0 баллов (подробнее о плагиате см. на странице курса). Если вы нашли решение какого-то из заданий (или его часть) в открытом источнике, необходимо указать ссылку на этот источник в отдельном блоке в конце вашей работы (скорее всего вы будете не единственным, кто это нашел, поэтому чтобы исключить подозрение в плагиате, необходима ссылка на источник).\n",
    "\n",
    "Неэффективная реализация кода может негативно отразиться на оценке.\n",
    "\n",
    "### Формат сдачи\n",
    "Задания сдаются через систему anytask. Посылка должна содержать:\n",
    "* Ноутбук homework-practice-08-random-features-Username.ipynb\n",
    "\n",
    "Username — ваша фамилия и имя на латинице именно в таком порядке"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vY8vT0W_K-hR"
   },
   "source": [
    "### О задании\n",
    "\n",
    "На занятиях мы подробно обсуждали метод опорных векторов (SVM). В базовой версии в нём нет чего-то особенного — мы всего лишь используем специальную функцию потерь, которая не требует устремлять отступы к бесконечности; ей достаточно, чтобы отступы были не меньше +1. Затем мы узнали, что SVM можно переписать в двойственном виде, который, позволяет заменить скалярные произведения объектов на ядра. Это будет соответствовать построению модели в новом пространстве более высокой размерности, координаты которого представляют собой нелинейные модификации исходных признаков.\n",
    "\n",
    "Ядровой SVM, к сожалению, довольно затратен по памяти (нужно хранить матрицу Грама размера $d \\times d$) и по времени (нужно решать задачу условной оптимизации с квадратичной функцией, а это не очень быстро). Мы обсуждали, что есть способы посчитать новые признаки $\\tilde \\varphi(x)$ на основе исходных так, что скалярные произведения этих новых $\\langle \\tilde \\varphi(x), \\tilde \\varphi(z) \\rangle$ приближают ядро $K(x, z)$.\n",
    "\n",
    "Мы будем исследовать аппроксимации методом Random Fourier Features (RFF, также в литературе встречается название Random Kitchen Sinks) для гауссовых ядер. Будем использовать формулы, которые немного отличаются от того, что было на лекциях (мы добавим сдвиги внутрь тригонометрических функций и будем использовать только косинусы, потому что с нужным сдвигом косинус превратится в синус):\n",
    "$$\\tilde \\varphi(x) = (\n",
    "\\cos (w_1^T x + b_1),\n",
    "\\dots,\n",
    "\\cos (w_n^T x + b_n)\n",
    "),$$\n",
    "где $w_j \\sim \\mathcal{N}(0, 1/\\sigma^2)$, $b_j \\sim U[-\\pi, \\pi]$.\n",
    "\n",
    "На новых признаках $\\tilde \\varphi(x)$ мы будем строить любую линейную модель.\n",
    "\n",
    "Можно считать, что это некоторая новая парадигма построения сложных моделей. Можно направленно искать сложные нелинейные закономерности в данных с помощью градиентного бустинга или нейронных сетей, а можно просто нагенерировать большое количество случайных нелинейных признаков и надеяться, что быстрая и простая модель (то есть линейная) сможет показать на них хорошее качество. В этом задании мы изучим, насколько работоспособна такая идея.\n",
    "\n",
    "### Алгоритм\n",
    "\n",
    "Вам потребуется реализовать следующий алгоритм:\n",
    "1. Понизить размерность выборки до new_dim с помощью метода главных компонент.\n",
    "2. Для полученной выборки оценить гиперпараметр $\\sigma^2$ с помощью эвристики (рекомендуем считать медиану не по всем парам объектов, а по случайному подмножеству из где-то миллиона пар объектов): $$\\sigma^2 = \\text{median}_{i, j = 1, \\dots, \\ell, i \\neq j} \\left\\{\\sum_{k = 1}^{d} (x_{ik} - x_{jk})^2 \\right\\}$$\n",
    "3. Сгенерировать n_features наборов весов $w_j$ и сдвигов $b_j$.\n",
    "4. Сформировать n_features новых признаков по формулам, приведённым выше.\n",
    "5. Обучить линейную модель (логистическую регрессию или SVM) на новых признаках.\n",
    "6. Повторить преобразования (PCA, формирование новых признаков) к тестовой выборке и применить модель."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N_sGunb7K-hS"
   },
   "source": [
    "Тестировать алгоритм мы будем на данных Fashion MNIST. Ниже код для их загрузки и подготовки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "YyG6dBfjK-hS"
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.datasets import fashion_mnist\n",
    "(x_train_pics, y_train), (x_test_pics, y_test) = fashion_mnist.load_data()\n",
    "x_train = x_train_pics.reshape(x_train_pics.shape[0], -1)\n",
    "x_test = x_test_pics.reshape(x_test_pics.shape[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rJNN55F7K-hT"
   },
   "source": [
    "__Задание 1. (5 баллов)__\n",
    "\n",
    "Реализуйте алгоритм, описанный выше. Можете воспользоваться шаблоном класса ниже или написать свой интерфейс.\n",
    "\n",
    "Ваша реализация должна поддерживать следующие опции:\n",
    "1. Возможность задавать значения гиперпараметров new_dim (по умолчанию 50) и n_features (по умолчанию 1000).\n",
    "2. Возможность включать или выключать предварительное понижение размерности с помощью метода главных компонент.\n",
    "3. Возможность выбирать тип линейной модели (логистическая регрессия или SVM с линейным ядром).\n",
    "\n",
    "Протестируйте на данных Fashion MNIST, сформированных кодом выше. Если на тесте у вас получилась доля верных ответов не ниже 0.84 с гиперпараметрами по умолчанию, то вы всё сделали правильно."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Примечание: в classifier будем сразу подавать линейную модель (для корректной работы должна иметь метод predict_proba или decision_function).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "jP8yepx8K-hT"
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import math\n",
    "import random\n",
    "\n",
    "class RFFPipeline(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, n_features=1000, new_dim=50, use_PCA=True, classifier=LogisticRegression()):\n",
    "        \"\"\"        \n",
    "        Implements pipeline, which consists of PCA decomposition,\n",
    "        Random Fourier Features approximation and linear classification model.\n",
    "        \n",
    "        n_features, int: amount of synthetic random features generated with RFF approximation.\n",
    "\n",
    "        new_dim, int: PCA output size.\n",
    "        \n",
    "        use_PCA, bool: whether to include PCA preprocessing.\n",
    "        \n",
    "        classifier, string: either 'svm' or 'logreg', a linear classification model to use on top of pipeline.\n",
    "        modified: classifier, linear classification model\n",
    "        \n",
    "        Feel free to edit this template for your preferences.    \n",
    "        \"\"\"\n",
    "        self.n_features = n_features\n",
    "        self.use_PCA = use_PCA\n",
    "        self.new_dim = new_dim\n",
    "        self.classifier = classifier\n",
    "    \n",
    "    def decode(self, i):    # for pair generator\n",
    "        k = math.floor((1+math.sqrt(1+8*i))/2)\n",
    "        return [k,i-k*(k-1)//2]\n",
    "\n",
    "    def rand_pairs(self, n, m):    # pair generator\n",
    "        return np.array([self.decode(i) for i in random.sample(range(n*(n-1)//2),m)])\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Fit all parts of algorithm (PCA, RFF, Classification) to training set.\n",
    "        \"\"\"\n",
    "        # Your code here: (￣▽￣)/♫•*¨*•.¸¸♪\n",
    "        if self.use_PCA:\n",
    "            self.pca_ = PCA(n_components=self.new_dim)\n",
    "            self.pca_.fit(X)\n",
    "            X = self.pca_.transform(X)\n",
    "        \n",
    "        idx = self.rand_pairs(X.shape[0], 1000000)\n",
    "        #idx = np.random.choice(range(X.shape[0]),size=(1000000, 2))\n",
    "        sigma_sq = np.median(((X[idx[:,0]] - X[idx[:,1]]) ** 2).sum(axis=1))\n",
    "        self.weights_ = np.random.normal(0, 1/np.sqrt(sigma_sq), (self.n_features, X.shape[1]))\n",
    "        self.intercept_ = np.random.uniform(-np.pi, np.pi, self.n_features)\n",
    "        X_new = np.cos(X.dot(self.weights_.T) + self.intercept_)\n",
    "\n",
    "        self.classifier.fit(X_new, y)\n",
    "        return self\n",
    "        raise NotImplementedError\n",
    "\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"\n",
    "        Apply pipeline to obtain scores for input data.\n",
    "        \"\"\"\n",
    "        # Your code here: (￣▽￣)/♫•*¨*•.¸¸♪\n",
    "        if self.use_PCA:\n",
    "            X = self.pca_.transform(X)\n",
    "\n",
    "        X_new = np.cos(X.dot(self.weights_.T) + self.intercept_)\n",
    "        if hasattr(self.classifier, 'predict_proba'):\n",
    "            return self.classifier.predict_proba(X_new)\n",
    "        else:\n",
    "            if hasattr(self.classifier, 'decision_function'):\n",
    "                return 1 / (1 + np.exp(-self.classifier.decision_function(X_new)))    # sigmoid\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Apply pipeline to obtain discrete predictions for input data.\n",
    "        \"\"\"\n",
    "        # Your code here: (￣▽￣)/♫•*¨*•.¸¸♪\n",
    "        if hasattr(self.classifier, 'classes_'):\n",
    "            return self.classifier.classes_[np.argmax(self.predict_proba(X), axis=1)]\n",
    "        return np.argmax(self.predict_proba(X), axis=1)\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Logistic regression:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RFFPipeline()"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rff_model = RFFPipeline()\n",
    "rff_model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.8751\n",
      "Test accuracy: 0.8580\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "preds_train = rff_model.predict(x_train)\n",
    "train_score = accuracy_score(y_train, preds_train)\n",
    "preds = rff_model.predict(x_test)\n",
    "test_score = accuracy_score(y_test, preds)\n",
    "\n",
    "print('Train accuracy: %.4f' % train_score)\n",
    "print('Test accuracy: %.4f' % test_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Linear SVM:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RFFPipeline(classifier=LinearSVC())"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rff_model_svm = RFFPipeline(classifier=LinearSVC())\n",
    "rff_model_svm.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.9093\n",
      "Test accuracy: 0.8727\n"
     ]
    }
   ],
   "source": [
    "preds_train_svm = rff_model_svm.predict(x_train)\n",
    "train_score_svm = accuracy_score(y_train, preds_train_svm)\n",
    "preds_svm = rff_model_svm.predict(x_test)\n",
    "test_score_svm = accuracy_score(y_test, preds_svm)\n",
    "\n",
    "print('Train accuracy: %.4f' % train_score_svm)\n",
    "print('Test accuracy: %.4f' % test_score_svm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HYqQUEi-K-hU"
   },
   "source": [
    "__Задание 2. (3 балла)__\n",
    "\n",
    "Сравните подход со случайными признаками с обучением SVM на исходных признаках. Попробуйте вариант с обычным (линейным) SVM и с ядровым SVM. Ядровой SVM может очень долго обучаться, поэтому можно делать любые разумные вещи для ускорения: брать подмножество объектов из обучающей выборки, например.\n",
    "\n",
    "Сравните подход со случайными признаками с вариантом, в котором вы понижаете размерность с помощью PCA и обучаете градиентный бустинг. Используйте одну из реализаций CatBoost/LightGBM/XGBoost, не забудьте подобрать число деревьев и длину шага.\n",
    "\n",
    "Сделайте выводы — насколько идея со случайными признаками работает? Сравните как с точки зрения качества, так и с точки зрения скорости обучения и применения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Рассмотрим скорость обучения (на x_train) и применения модели (на x_test) со случайными признаками:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4min 2s ± 34.7 s per loop (mean ± std. dev. of 3 runs, 1 loop each)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "%%timeit -r 3\n",
    "rff_model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.44 s ± 42.2 ms per loop (mean ± std. dev. of 3 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -r 3\n",
    "rff_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Модель обучается примерно за 4 минуты, применяется за 1.44 секунд.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Рассмотрим результаты модели SVM (линейную и с гауссовым ядром), скорость их обучения и применения:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "qN8LUlJgK-hV"
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "lin_svc = LinearSVC()\n",
    "kern_svc = SVC()    # default kernel = 'rbf' - gaussian\n",
    "subset_idx = random.sample(range(x_train.shape[0]), 20000)    # train on subset for faster learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear SVC fitting time: 771.9873 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "lin_svc.fit(x_train, y_train)\n",
    "print('Linear SVC fitting time: %.4f s' % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear SVC predicting time: 0.2680 s\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "lin_svc_preds = lin_svc.predict(x_test)\n",
    "print('Linear SVC predicting time: %.4f s' % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Линейный SVM обучается (на всём x_train) примерно за 12 минут, применяется за 0.27 секунд.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernel SVC fitting time: 216.8893 s\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "kern_svc.fit(x_train[subset_idx], y_train[subset_idx])\n",
    "print('Kernel SVC fitting time: %.4f s' % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernel SVC predicting time: 213.7479 s\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "kern_svc_preds = kern_svc.predict(x_test)\n",
    "print('Kernel SVC predicting time: %.4f s' % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Ядровой SVM обучается (на 20к объектах - третья часть x_train) примерно за 3.6 минут, применяется за 3.5 минуты.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_svc_train_preds = lin_svc.predict(x_train)\n",
    "kern_svc_train_preds = kern_svc.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear SVC on initial features:\n",
      "\t Train accuracy: 0.7806 \t Test accuracy: 0.7535\n",
      "Kernel SVC on initial features:\n",
      "\t Train accuracy: 0.8843 \t Test accuracy: 0.8672\n"
     ]
    }
   ],
   "source": [
    "lsvc_scores = (accuracy_score(y_train, lin_svc_train_preds), accuracy_score(y_test, lin_svc_preds))\n",
    "ksvc_scores = (accuracy_score(y_train, kern_svc_train_preds), accuracy_score(y_test, kern_svc_preds))\n",
    "\n",
    "print('Linear SVC on initial features:')\n",
    "print('\\t Train accuracy: %.4f \\t Test accuracy: %.4f' % lsvc_scores)\n",
    "print('Kernel SVC on initial features:')\n",
    "print('\\t Train accuracy: %.4f \\t Test accuracy: %.4f' % ksvc_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Как можно заметить, при использовании линейного SVM на исходных признаках точность (0.75) получается на 0.1 ниже результата работы модели со случайными признаками (0.85). При этом линейный SVM долго обучается (10-12 минут), поэтому из всех рассмотренных подходов эта модель является наименее удачной. Ядровой SVM по точности получается примерно таким же, как и модель с RFF (0.86), однако скорость его обучения и применения дольше (уже на трети выборки модель обучается 3.6 минут), более того, модель с RFF с использованием линейного SVM выдаёт более высокую точность (0.9 на обучающей выборке, 0.87 на тестовой, впрочем, скорость обучения значительно становится медленнее относительно модели c RFF с использованием логистической регрессии).*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Рассмотрим модель XGBoost с понижением размерности с PCA. Предварительно подберём значения числа деревьев и шага обучения:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[03:02:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:03:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:03:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:04:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:04:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:05:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:05:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:06:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:06:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:07:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:07:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:08:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:09:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:09:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:10:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:11:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:11:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:12:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:12:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:13:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:14:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:14:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:15:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:16:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:17:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:17:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:18:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[03:19:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:20:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:20:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:21:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:22:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:23:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:24:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:24:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:25:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:26:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:27:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:28:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:29:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:30:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:31:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:32:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:33:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:34:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:35:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:36:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:37:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:38:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:39:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:40:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:41:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:42:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:43:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[03:44:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:45:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:46:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:48:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:49:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:50:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:51:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:52:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:53:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:55:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:56:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:57:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:58:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[04:00:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[04:01:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[04:02:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from xgboost import XGBClassifier\n",
    "n_est_grid = np.arange(6,20,2)\n",
    "lr_grid = np.linspace(1e-6,1,10)\n",
    "\n",
    "best_xgb = None\n",
    "best_xgb_score = 0\n",
    "for n in n_est_grid:\n",
    "    for lr in lr_grid:\n",
    "        xgb = Pipeline([\n",
    "            ('pca', PCA(n_components=50)),\n",
    "            ('xgb', XGBClassifier(use_label_encoder=False,n_estimators=n, learning_rate=lr))\n",
    "        ])\n",
    "        xgb.fit(x_train, y_train)\n",
    "        xgb_score = accuracy_score(xgb.predict(x_test), y_test)\n",
    "        if (xgb_score > best_xgb_score):\n",
    "            best_xgb_score = xgb_score\n",
    "            best_xgb = xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:52:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "PCA + XGBoost fitting time: 80.7980 s\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "best_xgb.fit(x_train, y_train)\n",
    "print('PCA + XGBoost fitting time: %.4f s' % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "155 ms ± 2.99 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "best_xgb.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Время обучения модели PCA + XGBoost: 81 секунд, применения: 155 миллисекунд.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_train_preds = best_xgb.predict(x_train)\n",
    "xgb_preds = best_xgb.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA + XGBoost:\n",
      "\t Train accuracy: 0.9155 \t Test accuracy: 0.8504\n"
     ]
    }
   ],
   "source": [
    "print('PCA + XGBoost:')\n",
    "print('\\t Train accuracy: %.4f \\t Test accuracy: %.4f' % \n",
    "      (accuracy_score(y_train, xgb_train_preds),accuracy_score(y_test, xgb_preds)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Как можно заметить, по качеству работы модель с PCA и XGBoost похожа на результат модели с RFF и линейным SVM, однако точность у модели с бустингом на обучающей выборке выше (0.91, у RFF+SVM - 0.9), но на тестовой ниже (0.85, у RFF+SVM - 0.87). С другой стороны, модель с бустингом обучается и применяется в несколько раз быстрее (1.2 минуты и 155 мс, тогда как RFF+Logreg обучается за 4 минуты и применяется за 1 минуту, RFF+SVM обучается ещё медленнее). Поэтому, модель с понижением размерности с помощью PCA и использованием градиентного бустинга, как и модель со случайными признаками можно считать удачными.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e6umjhWuK-hV"
   },
   "source": [
    "__Задание 3. (2 балла)__\n",
    "\n",
    "Проведите эксперименты:\n",
    "1. Помогает ли предварительное понижение размерности с помощью PCA? \n",
    "2. Как зависит итоговое качество от n_features? Выходит ли оно на плато при росте n_features?\n",
    "3. Важно ли, какую модель обучать — логистическую регрессию или SVM?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) *Рассмотрим модель без PCA:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "c2QIHIMbK-hW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.1889\n",
      "Test accuracy: 0.1098\n"
     ]
    }
   ],
   "source": [
    "rff_no_pca = RFFPipeline(use_PCA=False)\n",
    "rff_no_pca.fit(x_train, y_train)\n",
    "\n",
    "no_pca_train_preds = rff_no_pca.predict(x_train)\n",
    "no_pca_preds = rff_no_pca.predict(x_test)\n",
    "\n",
    "print('Train accuracy: %.4f' % accuracy_score(y_train, no_pca_train_preds))\n",
    "print('Test accuracy: %.4f' % accuracy_score(y_test, no_pca_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Точность на тестовой выборке - 11%, тогда как в первом задании модель с использованием PCA дала результат в несколько раз лучше - 85%. Значит, предварительное понижение размерности с помощью PCA существенно влияет на качество модели.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Примечание: на этом моменте у меня умер kernel, поэтому нумерация немного непоследовательная.*\n",
    "\n",
    "2) *Рассмотрим зависимость качества модели от значения параметра n_features:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 4.47 GiB for an array with shape (60000, 10000) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-40c94c73920d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRFFPipeline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0macc_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m     \u001b[0macc_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-fa9b4b017f5a>\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m     83\u001b[0m         \"\"\"\n\u001b[0;32m     84\u001b[0m         \u001b[1;31m# Your code here: (￣▽￣)/♫•*¨*•.¸¸♪\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 85\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     86\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-fa9b4b017f5a>\u001b[0m in \u001b[0;36mpredict_proba\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m     70\u001b[0m             \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpca_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[0mX_new\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcos\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweights_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mintercept_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'predict_proba'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_new\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 4.47 GiB for an array with shape (60000, 10000) and data type float64"
     ]
    }
   ],
   "source": [
    "n_ft_grid = np.logspace(1,4,20)    # take int\n",
    "acc_train = []\n",
    "acc_test = []\n",
    "\n",
    "for n in n_ft_grid:\n",
    "    model = RFFPipeline(n_features = int(n))\n",
    "    model.fit(x_train, y_train)\n",
    "    acc_train.append(accuracy_score(y_train, model.predict(x_train)))\n",
    "    acc_test.append(accuracy_score(y_test, model.predict(x_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Примечание: на 10к признаков не хватило памяти (поэтому на графике берётся n_ft_grid[:-1]).*\n",
    "\n",
    "*Нарисуем график зависимости точности на обучающей и тестовой выборках в зависимости от n_features:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot([int(n) for n in n_ft_grid][:-1], acc_train, label='train')\n",
    "plt.plot([int(n) for n in n_ft_grid][:-1], acc_test, label='test')\n",
    "plt.xlabel('number of features')\n",
    "plt.ylabel('accuracy')\n",
    "plt.title('PCA + RFF accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy values: min = 0.6075, max = 0.8782\n",
      "Test accuracy values: min = 0.5929, max = 0.8619\n"
     ]
    }
   ],
   "source": [
    "print('Train accuracy values: min = %.4f, max = %.4f' % (min(acc_train), max(acc_train)))\n",
    "print('Test accuracy values: min = %.4f, max = %.4f' % (min(acc_test), max(acc_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy >= 0.87 beginning from n_features = 545\n",
      "Test accuracy >= 0.85 beginning from n_features = 379\n"
     ]
    }
   ],
   "source": [
    "print('Train accuracy >= 0.87 beginning from n_features = %d' % n_ft_grid[np.argmax(np.array(acc_train) >= 0.87)])\n",
    "print('Test accuracy >= 0.85 beginning from n_features = %d' % n_ft_grid[np.argmax(np.array(acc_test) >= 0.85)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Как можно заметить, с увеличением числа признаков качество модели улучшается и выходит на константу (от 0.6 при 10 признаках до 0.87) уже при 300-600 признаках.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) *Повторим полученные в первом задании результаты, дополнительно сравним время работы модели с логистической регрессией и линейным SVM:*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Logistic regression:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RFF + Logistic regression fitting time: 192.2427 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "rff_model = RFFPipeline()\n",
    "start_time = time.time()\n",
    "rff_model.fit(x_train, y_train)\n",
    "print('RFF + Logistic regression fitting time: %.4f s' % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RFF + Logistic regression predicting time: 0.7670 s\n",
      "Train accuracy: 0.8740\n",
      "Test accuracy: 0.8594\n"
     ]
    }
   ],
   "source": [
    "preds_train = rff_model.predict(x_train)\n",
    "train_score = accuracy_score(y_train, preds_train)\n",
    "start_time = time.time()\n",
    "preds = rff_model.predict(x_test)\n",
    "print('RFF + Logistic regression predicting time: %.4f s' % (time.time() - start_time))\n",
    "test_score = accuracy_score(y_test, preds)\n",
    "\n",
    "print('Train accuracy: %.4f' % train_score)\n",
    "print('Test accuracy: %.4f' % test_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Linear SVM:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RFF + Linear SVM fitting time: 696.8158 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    }
   ],
   "source": [
    "rff_model_svm = RFFPipeline(classifier=LinearSVC())\n",
    "start_time = time.time()\n",
    "rff_model_svm.fit(x_train, y_train)\n",
    "print('RFF + Linear SVM fitting time: %.4f s' % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RFF + Linear SVM fitting time: 0.7899 s\n",
      "Train accuracy: 0.9092\n",
      "Test accuracy: 0.8722\n"
     ]
    }
   ],
   "source": [
    "preds_train_svm = rff_model_svm.predict(x_train)\n",
    "train_score_svm = accuracy_score(y_train, preds_train_svm)\n",
    "start_time = time.time()\n",
    "preds_svm = rff_model_svm.predict(x_test)\n",
    "print('RFF + Linear SVM fitting time: %.4f s' % (time.time() - start_time))\n",
    "test_score_svm = accuracy_score(y_test, preds_svm)\n",
    "\n",
    "print('Train accuracy: %.4f' % train_score_svm)\n",
    "print('Test accuracy: %.4f' % test_score_svm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Из результатов можно увидеть, что модели отличаются по времени работы и по качеству.*\n",
    "\n",
    "*На логистической регрессии модель обучается примерно 3 минуты, а применяется за 0.8 секунд, с линейным SVM модель обучается примерно 11-12 минут и применяется примерно за 0.8 секунд.*\n",
    "\n",
    "*Таким образом, модель на SVM обучается дольше (но время применения одно и то же), однако точность её предсказаний выше - у логистической регрессии - 0.87 и 0.86 на обучающей и тестовой выборке соответственно, а у SVM - 0.9 и 0.87.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CJqXVuasK-hW"
   },
   "source": [
    "### Бонус"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QVDWHCdrK-hX"
   },
   "source": [
    "__Задание 4. (Максимум 2 балла)__\n",
    "\n",
    "Как вы, должно быть, помните с курса МО-1, многие алгоритмы машинного обучения работают лучше, если признаки данных некоррелированы. Оказывается, что для RFF существует модификация, позволяющая получать ортогональные случайные признаки (Orthogonal Random Features, ORF). Об этом методе можно прочитать в [статье](https://proceedings.neurips.cc/paper/2016/file/53adaf494dc89ef7196d73636eb2451b-Paper.pdf). Реализуйте класс для вычисления ORF по аналогии с основным заданием. Обратите внимание, что ваш класс должен уметь работать со случаем n_features > new_dim (в статье есть замечание на этот счет). Проведите эксперименты, сравнивающие RFF и ORF, сделайте выводы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "HSxvGI9iK-hX"
   },
   "outputs": [],
   "source": [
    "class ORFPipeline(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, n_features=1000, new_dim=50, use_PCA=True, ft_func = np.cos, classifier=LogisticRegression()):\n",
    "        \"\"\"        \n",
    "        Implements pipeline, which consists of PCA decomposition,\n",
    "        Orthogonal Random Features approximation and linear classification model.\n",
    "        \n",
    "        n_features, int: amount of synthetic random features generated with ORF approximation.\n",
    "\n",
    "        new_dim, int: PCA output size.\n",
    "        \n",
    "        use_PCA, bool: whether to include PCA preprocessing.\n",
    "        \n",
    "        ft_func, function(np.array): function to implement on w^Tx+b for new features generation\n",
    "        \n",
    "        classifier, linear classification model        \n",
    "        \"\"\"\n",
    "        self.n_features = n_features\n",
    "        self.use_PCA = use_PCA\n",
    "        self.new_dim = new_dim\n",
    "        self.ft_func = ft_func\n",
    "        self.classifier = classifier\n",
    "    \n",
    "    def decode(self, i):    # for pair generator\n",
    "        k = math.floor((1+math.sqrt(1+8*i))/2)\n",
    "        return [k,i-k*(k-1)//2]\n",
    "\n",
    "    def rand_pairs(self, n, m):    # pair generator\n",
    "        return np.array([self.decode(i) for i in random.sample(range(n*(n-1)//2),m)])\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Fit all parts of algorithm (PCA, RFF, Classification) to training set.\n",
    "        \"\"\"\n",
    "        if self.use_PCA:\n",
    "            self.pca_ = PCA(n_components=self.new_dim)\n",
    "            self.pca_.fit(X)\n",
    "            X = self.pca_.transform(X)\n",
    "        \n",
    "        idx = self.rand_pairs(X.shape[0], 1000000)\n",
    "        sigma_sq = np.median(((X[idx[:,0]] - X[idx[:,1]]) ** 2).sum(axis=1))\n",
    "        self.sigma_sq = sigma_sq\n",
    "        d = X.shape[1]\n",
    "        m = math.ceil(self.n_features / d)\n",
    "        self.intercept_ = []\n",
    "        self.weights_ = []\n",
    "        for i in range(m):\n",
    "            G = np.random.normal(0,1, (d, d))    # Gaussian matrix\n",
    "            self.intercept_ += [np.random.uniform(-np.pi, np.pi, d)]\n",
    "            Q, _ = np.linalg.qr(G)    # Q from QR-decomposition of G\n",
    "            S = np.diagflat(np.sqrt(np.random.chisquare(d, d)))    # diag values from chi with dof = d\n",
    "            self.weights_ += [S @ Q]\n",
    "        self.intercept_ = np.array(self.intercept_).flatten()\n",
    "        self.weights_ = np.vstack(self.weights_)\n",
    "        \n",
    "        X_new = self.ft_func((X.dot(self.weights_.T) + self.intercept_)[:,:self.n_features] / np.sqrt(sigma_sq))\n",
    "        \n",
    "        self.classifier.fit(X_new, y)\n",
    "        return self\n",
    "        raise NotImplementedError\n",
    "\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"\n",
    "        Apply pipeline to obtain scores for input data.\n",
    "        \"\"\"\n",
    "        if self.use_PCA:\n",
    "            X = self.pca_.transform(X)\n",
    "\n",
    "        X_new = self.ft_func((X.dot(self.weights_.T) + self.intercept_)[:,:self.n_features] / np.sqrt(self.sigma_sq))\n",
    "\n",
    "        if hasattr(self.classifier, 'predict_proba'):\n",
    "            return self.classifier.predict_proba(X_new)\n",
    "        else:\n",
    "            if hasattr(self.classifier, 'decision_function'):\n",
    "                return 1 / (1 + np.exp(-self.classifier.decision_function(X_new)))    # sigmoid\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Apply pipeline to obtain discrete predictions for input data.\n",
    "        \"\"\"\n",
    "        if hasattr(self.classifier, 'classes_'):\n",
    "            return self.classifier.classes_[np.argmax(self.predict_proba(X), axis=1)]\n",
    "        return np.argmax(self.predict_proba(X), axis=1)\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Рассмотрим работу модели с логистической регрессией и линейным SVM:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORF + Logistic Regression fitting time: 50.9287 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "orf_model = ORFPipeline()\n",
    "start_time = time.time()\n",
    "orf_model.fit(x_train, y_train)\n",
    "print('ORF + Logistic Regression fitting time: %.4f s' % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORF + Logistic regression predicting time: 0.4518 s\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "orf_preds = orf_model.predict(x_test)\n",
    "print('ORF + Logistic regression predicting time: %.4f s' % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORF + Logistic regression:\n",
      "\t Train accuracy: 0.8621 \t Test accuracy: 0.8494\n"
     ]
    }
   ],
   "source": [
    "orf_train_preds = orf_model.predict(x_train)\n",
    "print('ORF + Logistic regression:')\n",
    "print('\\t Train accuracy: %.4f \\t Test accuracy: %.4f' % (accuracy_score(y_train, orf_train_preds), \n",
    "                                                          accuracy_score(y_test, orf_preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORF + Linear SVC fitting time: 494.8429 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    }
   ],
   "source": [
    "orf_svc_model = ORFPipeline(classifier=LinearSVC())\n",
    "start_time = time.time()\n",
    "orf_svc_model.fit(x_train, y_train)\n",
    "print('ORF + Linear SVC fitting time: %.4f s' % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORF + Linear SVC predicting time: 0.4977 s\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "orf_svc_preds = orf_svc_model.predict(x_test)\n",
    "print('ORF + Linear SVC predicting time: %.4f s' % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORF + Linear SVC:\n",
      "\t Train accuracy: 0.9064 \t Test accuracy: 0.8744\n"
     ]
    }
   ],
   "source": [
    "orf_svc_train_preds = orf_svc_model.predict(x_train)\n",
    "print('ORF + Linear SVC:')\n",
    "print('\\t Train accuracy: %.4f \\t Test accuracy: %.4f' % (accuracy_score(y_train, orf_svc_train_preds), \n",
    "                                                          accuracy_score(y_test, orf_svc_preds)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Для сравнения выведем ещё раз результаты из первого задания (с моделью c RRF):*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RRF + Logistic regression:\n",
      "\t Train accuracy: 0.8740 \t Test accuracy: 0.8594\n"
     ]
    }
   ],
   "source": [
    "rrf_train_preds = rff_model.predict(x_train)\n",
    "rrf_preds = rff_model.predict(x_test)\n",
    "print('RRF + Logistic regression:')\n",
    "print('\\t Train accuracy: %.4f \\t Test accuracy: %.4f' % (accuracy_score(y_train, rrf_train_preds), \n",
    "                                                          accuracy_score(y_test, rrf_preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RRF + Linear SVC:\n",
      "\t Train accuracy: 0.9092 \t Test accuracy: 0.8722\n"
     ]
    }
   ],
   "source": [
    "rrf_svc_train_preds = rff_model_svm.predict(x_train)\n",
    "rrf_svc_preds = rff_model_svm.predict(x_test)\n",
    "print('RRF + Linear SVC:')\n",
    "print('\\t Train accuracy: %.4f \\t Test accuracy: %.4f' % (accuracy_score(y_train, rrf_svc_train_preds), \n",
    "                                                          accuracy_score(y_test, rrf_svc_preds)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Как можно заметить, результаты на логистической регрессии у модели с ORF на 0.01 хуже модели с RRF, а на линейном SVM модель с ORF показывает примерно такой же результат, что и модель с RRF. Таким образом, в качестве на моделях с гиперпараметрами по умолчанию (new_dim=50, n_features=1000) значимого улучшения не наблюдается.*\n",
    "\n",
    "*Стоит отметить, что модель с ORF работает в несколько раз быстрее модели c RRF (на логистической регрессии обучается меньше минуты, применяется за 0.5 секунд, тогда как модель с RRF работает при тех же параметрах 3-4 минуты и предсказывает за 2 секунды, на линейном SVM также заметно существенное ускорение: с 11 минут до 8 минут).*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Посмотрим на зависимость точности от значения n_features в этой модели:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "n_ft_grid = np.logspace(1,3.8,10)    # take int\n",
    "orf_acc_train = []\n",
    "orf_acc_test = []\n",
    "\n",
    "for n in n_ft_grid:\n",
    "    model = ORFPipeline(n_features = int(n))\n",
    "    model.fit(x_train, y_train)\n",
    "    orf_acc_train.append(accuracy_score(y_train, model.predict(x_train)))\n",
    "    orf_acc_test.append(accuracy_score(y_test, model.predict(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot([int(n) for n in n_ft_grid], orf_acc_train, label='train')\n",
    "plt.plot([int(n) for n in n_ft_grid], orf_acc_test, label='test')\n",
    "plt.xlabel('number of features')\n",
    "plt.ylabel('accuracy')\n",
    "plt.title('PCA + ORF accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Видим, что график получается похожим на график для модели с RRF (где-то с 300-400 значения точности выходит на константу около 0.86).*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Рассмотрим точность в зависимости от отношения n_features / new_dim (аналогично анализу в статье):*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "acc_rff = []\n",
    "acc_orf = []\n",
    "for m in range(1,11):\n",
    "    rff_model_ = RFFPipeline(new_dim=50, n_features = 50 * m)\n",
    "    orf_model_ = ORFPipeline(new_dim=50, n_features = 50 * m)\n",
    "    rff_model_.fit(x_train, y_train)\n",
    "    orf_model_.fit(x_train, y_train)\n",
    "    acc_rff.append(accuracy_score(y_test, rff_model_.predict(x_test)))\n",
    "    acc_orf.append(accuracy_score(y_test, orf_model_.predict(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(1,11), acc_rff, label='RFF')\n",
    "plt.plot(range(1,11), acc_orf, label='ORF')\n",
    "plt.xlabel('n_features / new_dim (new_dim = 50)')\n",
    "plt.ylabel('accuracy')\n",
    "plt.title('Accuracy on RRF vs ORF')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Получаем, что в среднем логистическая регрессия на ORF работает несколько хуже, чем на RRF (впрочем, с увеличением отношения n_features / new_dim разница значительно уменьшается), однако модель с ORF работает намного быстрее.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4pc7-1jmK-hY"
   },
   "source": [
    "__Задание 5. (Максимум 2 балла)__\n",
    "\n",
    "Поэкспериментируйте с функциями для вычисления новых случайных признаков. Не обязательно использовать косинус от скалярного произведения — можно брать знак от него, хэш и т.д. Придумайте побольше вариантов для генерации признаков и проверьте, не получается ли с их помощью добиваться более высокого качества. Также можете попробовать другой классификатор поверх случайных признаков, сравните результаты."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Добавим в класс возможность задавать функцию получения признаков (по умолчанию np.cos()):*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "dWj-O2vjK-hY"
   },
   "outputs": [],
   "source": [
    "class RFFPipeline_2(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, n_features=1000, new_dim=50, use_PCA=True, ft_func = np.cos, classifier=LogisticRegression()):\n",
    "        \"\"\"        \n",
    "        Implements pipeline, which consists of PCA decomposition,\n",
    "        Random Fourier Features approximation and linear classification model.\n",
    "        \n",
    "        n_features, int: amount of synthetic random features generated with RFF approximation.\n",
    "\n",
    "        new_dim, int: PCA output size.\n",
    "        \n",
    "        use_PCA, bool: whether to include PCA preprocessing.\n",
    "        \n",
    "        ft_func, function(np.array): function to implement on w^Tx+b for new features generation\n",
    "        \n",
    "        classifier, linear classification model        \n",
    "        \"\"\"\n",
    "        self.n_features = n_features\n",
    "        self.use_PCA = use_PCA\n",
    "        self.new_dim = new_dim\n",
    "        self.ft_func = ft_func\n",
    "        self.classifier = classifier\n",
    "    \n",
    "    def decode(self, i):    # for pair generator\n",
    "        k = math.floor((1+math.sqrt(1+8*i))/2)\n",
    "        return [k,i-k*(k-1)//2]\n",
    "\n",
    "    def rand_pairs(self, n, m):    # pair generator\n",
    "        return np.array([self.decode(i) for i in random.sample(range(n*(n-1)//2),m)])\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Fit all parts of algorithm (PCA, RFF, Classification) to training set.\n",
    "        \"\"\"\n",
    "        if self.use_PCA:\n",
    "            self.pca_ = PCA(n_components=self.new_dim)\n",
    "            self.pca_.fit(X)\n",
    "            X = self.pca_.transform(X)\n",
    "        \n",
    "        idx = self.rand_pairs(X.shape[0], 1000000)\n",
    "        sigma_sq = np.median(((X[idx[:,0]] - X[idx[:,1]]) ** 2).sum(axis=1))\n",
    "        self.weights_ = np.random.normal(0, 1/np.sqrt(sigma_sq), (self.n_features, X.shape[1]))\n",
    "        self.intercept_ = np.random.uniform(-np.pi, np.pi, self.n_features)\n",
    "        X_new = self.ft_func(X.dot(self.weights_.T) + self.intercept_)\n",
    "\n",
    "        self.classifier.fit(X_new, y)\n",
    "        return self\n",
    "        raise NotImplementedError\n",
    "\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"\n",
    "        Apply pipeline to obtain scores for input data.\n",
    "        \"\"\"\n",
    "        if self.use_PCA:\n",
    "            X = self.pca_.transform(X)\n",
    "\n",
    "        X_new = self.ft_func(X.dot(self.weights_.T) + self.intercept_)\n",
    "        if hasattr(self.classifier, 'predict_proba'):\n",
    "            return self.classifier.predict_proba(X_new)\n",
    "        else:\n",
    "            if hasattr(self.classifier, 'decision_function'):\n",
    "                return 1 / (1 + np.exp(-self.classifier.decision_function(X_new)))    # sigmoid\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Apply pipeline to obtain discrete predictions for input data.\n",
    "        \"\"\"\n",
    "        if hasattr(self.classifier, 'classes_'):\n",
    "            return self.classifier.classes_[np.argmax(self.predict_proba(X), axis=1)]\n",
    "        return np.argmax(self.predict_proba(X), axis=1)\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Рассмотрим модель с взятием знака, сигмоиды, tanh от скалярного произведения. Также рассмотрим использование SGDClassifier(), DecisionTreeClassifier(), RandomForestClassifier().*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "def sigmoid(X):\n",
    "    return 1 / (1 + np.exp(-X))\n",
    "\n",
    "ft_functions = [np.cos, np.sign, sigmoid, np.tanh]\n",
    "lin_classifiers = [LogisticRegression(), SGDClassifier(), DecisionTreeClassifier(), RandomForestClassifier(n_estimators=10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                            | 0/4 [00:00<?, ?it/s]C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      " 25%|████████████████████▊                                                              | 1/4 [01:46<05:18, 106.23s/it]C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      " 50%|█████████████████████████████████████████▌                                         | 2/4 [03:29<03:30, 105.25s/it]C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      " 75%|██████████████████████████████████████████████████████████████▎                    | 3/4 [05:18<01:46, 106.55s/it]C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 4/4 [07:17<00:00, 109.46s/it]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 4/4 [10:38<00:00, 159.52s/it]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 4/4 [29:02<00:00, 435.72s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 4/4 [05:20<00:00, 80.09s/it]\n"
     ]
    }
   ],
   "source": [
    "time_dict = dict()\n",
    "acc_dict = dict()\n",
    "\n",
    "for classifier in lin_classifiers:\n",
    "    time_dict[str(classifier)] = dict()\n",
    "    acc_dict[str(classifier)] = dict()\n",
    "    for ft_func in tqdm(ft_functions):\n",
    "        model = RFFPipeline_2(ft_func=ft_func, classifier=classifier)\n",
    "        start_time = time.time()\n",
    "        model.fit(x_train, y_train)\n",
    "        fit_time = time.time() - start_time\n",
    "        \n",
    "        start_time = time.time()\n",
    "        preds = model.predict(x_test)\n",
    "        pred_time = time.time() - start_time\n",
    "        \n",
    "        train_preds = model.predict(x_train)\n",
    "        \n",
    "        time_dict[str(classifier)][str(ft_func)] = (fit_time, pred_time)\n",
    "        acc_dict[str(classifier)][str(ft_func)] = (accuracy_score(y_train, train_preds), accuracy_score(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression() <ufunc 'cos'>\n",
      "\tFitting time: 99.5319 s\t Predicting time: 1.0554 s\n",
      "\tTrain accuracy: 0.8747\t Test accuracy: 0.8574 s\n",
      "LogisticRegression() <ufunc 'sign'>\n",
      "\tFitting time: 97.8593 s\t Predicting time: 0.8657 s\n",
      "\tTrain accuracy: 0.8558\t Test accuracy: 0.8345 s\n",
      "LogisticRegression() <function sigmoid at 0x00000201238AC670>\n",
      "\tFitting time: 100.9011 s\t Predicting time: 1.2955 s\n",
      "\tTrain accuracy: 0.8285\t Test accuracy: 0.8136 s\n",
      "LogisticRegression() <ufunc 'tanh'>\n",
      "\tFitting time: 109.9661 s\t Predicting time: 1.2831 s\n",
      "\tTrain accuracy: 0.8533\t Test accuracy: 0.8415 s\n",
      "SGDClassifier() <ufunc 'cos'>\n",
      "\tFitting time: 155.5777 s\t Predicting time: 1.2088 s\n",
      "\tTrain accuracy: 0.8844\t Test accuracy: 0.8605 s\n",
      "SGDClassifier() <ufunc 'sign'>\n",
      "\tFitting time: 185.0296 s\t Predicting time: 0.6363 s\n",
      "\tTrain accuracy: 0.8141\t Test accuracy: 0.7968 s\n",
      "SGDClassifier() <function sigmoid at 0x00000201238AC670>\n",
      "\tFitting time: 135.9945 s\t Predicting time: 0.9744 s\n",
      "\tTrain accuracy: 0.8393\t Test accuracy: 0.8247 s\n",
      "SGDClassifier() <ufunc 'tanh'>\n",
      "\tFitting time: 135.3076 s\t Predicting time: 1.0602 s\n",
      "\tTrain accuracy: 0.8676\t Test accuracy: 0.8472 s\n",
      "DecisionTreeClassifier() <ufunc 'cos'>\n",
      "\tFitting time: 507.4752 s\t Predicting time: 0.8769 s\n",
      "\tTrain accuracy: 1.0000\t Test accuracy: 0.7692 s\n",
      "DecisionTreeClassifier() <ufunc 'sign'>\n",
      "\tFitting time: 51.7454 s\t Predicting time: 0.7291 s\n",
      "\tTrain accuracy: 1.0000\t Test accuracy: 0.7585 s\n",
      "DecisionTreeClassifier() <function sigmoid at 0x00000201238AC670>\n",
      "\tFitting time: 651.5779 s\t Predicting time: 1.1217 s\n",
      "\tTrain accuracy: 1.0000\t Test accuracy: 0.7829 s\n",
      "DecisionTreeClassifier() <ufunc 'tanh'>\n",
      "\tFitting time: 507.0004 s\t Predicting time: 1.0803 s\n",
      "\tTrain accuracy: 1.0000\t Test accuracy: 0.7723 s\n",
      "RandomForestClassifier(n_estimators=10) <ufunc 'cos'>\n",
      "\tFitting time: 87.4959 s\t Predicting time: 0.9325 s\n",
      "\tTrain accuracy: 0.9949\t Test accuracy: 0.8301 s\n",
      "RandomForestClassifier(n_estimators=10) <ufunc 'sign'>\n",
      "\tFitting time: 28.1916 s\t Predicting time: 0.7093 s\n",
      "\tTrain accuracy: 0.9946\t Test accuracy: 0.8181 s\n",
      "RandomForestClassifier(n_estimators=10) <function sigmoid at 0x00000201238AC670>\n",
      "\tFitting time: 88.6457 s\t Predicting time: 1.0871 s\n",
      "\tTrain accuracy: 0.9949\t Test accuracy: 0.8375 s\n",
      "RandomForestClassifier(n_estimators=10) <ufunc 'tanh'>\n",
      "\tFitting time: 89.0382 s\t Predicting time: 1.2451 s\n",
      "\tTrain accuracy: 0.9953\t Test accuracy: 0.8382 s\n"
     ]
    }
   ],
   "source": [
    "for classifier in lin_classifiers:\n",
    "    for ft_func in ft_functions:\n",
    "        class_name = str(classifier)\n",
    "        func_name = str(ft_func)\n",
    "        print(class_name, func_name)\n",
    "        print('\\tFitting time: %.4f s\\t Predicting time: %.4f s' % time_dict[class_name][func_name])\n",
    "        print('\\tTrain accuracy: %.4f\\t Test accuracy: %.4f s' % acc_dict[class_name][func_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cos</th>\n",
       "      <th>sgn</th>\n",
       "      <th>sigmoid</th>\n",
       "      <th>tanh</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LogReg</th>\n",
       "      <td>0.8747, 0.8574</td>\n",
       "      <td>0.8558, 0.8345</td>\n",
       "      <td>0.8285, 0.8136</td>\n",
       "      <td>0.8533, 0.8415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SGDClassifier</th>\n",
       "      <td>0.8844, 0.8605</td>\n",
       "      <td>0.8141, 0.7968</td>\n",
       "      <td>0.8393, 0.8247</td>\n",
       "      <td>0.8676, 0.8472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DT</th>\n",
       "      <td>1.0000, 0.7692</td>\n",
       "      <td>1.0000, 0.7585</td>\n",
       "      <td>1.0000, 0.7829</td>\n",
       "      <td>1.0000, 0.7723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF</th>\n",
       "      <td>0.9949, 0.8301</td>\n",
       "      <td>0.9946, 0.8181</td>\n",
       "      <td>0.9949, 0.8375</td>\n",
       "      <td>0.9953, 0.8382</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          cos             sgn         sigmoid            tanh\n",
       "LogReg         0.8747, 0.8574  0.8558, 0.8345  0.8285, 0.8136  0.8533, 0.8415\n",
       "SGDClassifier  0.8844, 0.8605  0.8141, 0.7968  0.8393, 0.8247  0.8676, 0.8472\n",
       "DT             1.0000, 0.7692  1.0000, 0.7585  1.0000, 0.7829  1.0000, 0.7723\n",
       "RF             0.9949, 0.8301  0.9946, 0.8181  0.9949, 0.8375  0.9953, 0.8382"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame([['%.4f, %.4f' % acc_dict[class_dict][key] for key in acc_dict[class_dict]] for class_dict in acc_dict], \n",
    "             columns=['cos', 'sgn', 'sigmoid', 'tanh'],\n",
    "            index=['LogReg', 'SGDClassifier', 'DT', 'RF'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cos</th>\n",
       "      <th>sgn</th>\n",
       "      <th>sigmoid</th>\n",
       "      <th>tanh</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LogReg</th>\n",
       "      <td>99.53, 1.06</td>\n",
       "      <td>97.86, 0.87</td>\n",
       "      <td>100.90, 1.30</td>\n",
       "      <td>109.97, 1.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SGDClassifier</th>\n",
       "      <td>155.58, 1.21</td>\n",
       "      <td>185.03, 0.64</td>\n",
       "      <td>135.99, 0.97</td>\n",
       "      <td>135.31, 1.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DT</th>\n",
       "      <td>507.48, 0.88</td>\n",
       "      <td>51.75, 0.73</td>\n",
       "      <td>651.58, 1.12</td>\n",
       "      <td>507.00, 1.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF</th>\n",
       "      <td>87.50, 0.93</td>\n",
       "      <td>28.19, 0.71</td>\n",
       "      <td>88.65, 1.09</td>\n",
       "      <td>89.04, 1.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        cos           sgn       sigmoid          tanh\n",
       "LogReg          99.53, 1.06   97.86, 0.87  100.90, 1.30  109.97, 1.28\n",
       "SGDClassifier  155.58, 1.21  185.03, 0.64  135.99, 0.97  135.31, 1.06\n",
       "DT             507.48, 0.88   51.75, 0.73  651.58, 1.12  507.00, 1.08\n",
       "RF              87.50, 0.93   28.19, 0.71   88.65, 1.09   89.04, 1.25"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame([['%.2f, %.2f' % time_dict[class_dict][key] for key in time_dict[class_dict]] for class_dict in time_dict], \n",
    "             columns=['cos', 'sgn', 'sigmoid', 'tanh'],\n",
    "            index=['LogReg', 'SGDClassifier', 'DT', 'RF'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Проанализировав результаты, можно увидеть, что дольше всего обучается DecisionTreeClassifier() с значениями параметров по уолчанию, быстрее всего - RF на 10 деревьях (однако видно, что эти модели переобучаются). По качеству на тестовой выборке наилучший результат получился при взятии cos и использовании SGDClassifier() (впрочем, в первом задании при взятии cos и использовании линейного SVM точность выходила ещё выше). Из рассмотренных функций наименьшую точность дают взятие знака и сигмоиды, наилучшую - cos и tanh. Вероятно, при подборе гиперпараметров для SGDClassifier точность могла бы получиться ещё выше.*"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "homework-practice-08-random-features.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
